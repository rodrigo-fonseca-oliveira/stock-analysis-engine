apiVersion: batch/v1
kind: Job
metadata:
  name: sa-dataset-backup-to-minio
  annotations:
    description: The Stock Analysis Dataset Backup to S3 job. This will loop over all the DEFAULT_TICKERS and extract then publish them to the configured S3_ADDRESS endpoint. Set your secrets in the /opt/sa/k8/secrets/secrets.yml file under the ae.k8.minio.s3 section. Then start with kubectl apply -f /opt/jay/sa/k8/secrets/secrets.yml to add your minio credentials to this job's runtime.
    runtime: python3
  labels:
    sa: engine
    purpose: stock-analysis
    layer: backend
    messaging: redis
    cache: redis
    pubsub: publisher
spec:
  template:
    metadata:
      labels:
        app: sa-dataset-backup-to-minio
        backend: enabled
        purpose: stock-analysis
        layer: backend
        messaging: redis
        cache: redis
        pubsub: publisher
    spec:
      hostname: sa-dataset-backup-to-minio
      restartPolicy: Never
      containers:
      - image: jayjohnson/stock-analysis-engine:latest
        imagePullPolicy: Always
        name: sa-dataset-backup-to-minio
        resources: {}
        command: ["/bin/bash", "-c", "cd /opt/sa/ && . /opt/venv/bin/activate && /opt/sa/tools/archive-tickers-to-s3.sh -q ${S3_BUCKET}"]
        env:
        - name: POSTGRES_USER
          valueFrom:
            secretKeyRef:
              name: api.db
              key: username
        - name: POSTGRES_PASSWORD
          valueFrom:
            secretKeyRef:
              name: api.db
              key: password
        - name: POSTGRES_DB
          valueFrom:
            secretKeyRef:
              name: api.db
              key: dbname
        - name: S3_ACCESS_KEY
          valueFrom:
            secretKeyRef:
              name: ae.k8.minio.s3
              key: aws_access_key_id
        - name: S3_SECRET_KEY
          valueFrom:
            secretKeyRef:
              name: ae.k8.minio.s3
              key: aws_secret_access_key
        - name: S3_ADDRESS
          valueFrom:
            secretKeyRef:
              name: ae.k8.minio.s3
              key: s3_address
        - name: S3_REGION_NAME
          value: us-east-1
        - name: WORKER_BROKER_URL
          value: redis://redis-master:6379/13
        - name: WORKER_BACKEND_URL
          value: redis://redis-master:6379/14
        - name: REDIS_ADDRESS
          value: redis-master:6379
        - name: REDIS_DB
          value: "0"
        # Stock Analysis - Dataset Backup to hosted Minio S3 Envs:
        - name: S3_BUCKET
          value: YOUR_BUCKET
        - name: DEFAULT_TICKERS
          value: SPY,TSLA,AMZN,NFLX
        # set to your Slack webhook url:
        - name: SLACK_WEBHOOK
          valueFrom:
            secretKeyRef:
              name: ae.k8.slack
              key: webhook
          # set to your Slack OAuth Access Token or Bot User OAuth Access Token
        - name: SLACK_ACCESS_TOKEN
          valueFrom:
            secretKeyRef:
              name: ae.k8.slack
              key: access_token
          # set comma separated Slack channels (without '#') to publish plots to
        - name: SLACK_PUBLISH_PLOT_CHANNELS
          valueFrom:
            secretKeyRef:
              name: ae.k8.slack
              key: channels
        # set to "1" to enable publishing to slack when
        # each ticker's job completes
        - name: DATASET_COLLECTION_SLACK_ALERTS
          value: "0"
        # set to "1" to publish Celery task failures to Slack
        - name: PROD_SLACK_ALERTS
          value: "0"
